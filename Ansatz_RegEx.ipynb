{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import markovify\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>It is a stunner by any stretch of the imaginat...</td>\n",
       "      <td>06-05-2020 13:01:38</td>\n",
       "      <td>38831.0</td>\n",
       "      <td>1.268891e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>It’s a stupendous number. It’s joyous let’s ca...</td>\n",
       "      <td>06-05-2020 12:59:17</td>\n",
       "      <td>35164.0</td>\n",
       "      <td>1.268890e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Oh no the Dems are worried again. The only one...</td>\n",
       "      <td>06-05-2020 12:54:18</td>\n",
       "      <td>59423.0</td>\n",
       "      <td>1.268889e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Congratulations to wonderful Charles Payne on ...</td>\n",
       "      <td>06-05-2020 12:51:00</td>\n",
       "      <td>45021.0</td>\n",
       "      <td>1.268888e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I will be doing a News Conference at 10:00 A.M...</td>\n",
       "      <td>06-05-2020 12:48:41</td>\n",
       "      <td>59473.0</td>\n",
       "      <td>1.268887e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  It is a stunner by any stretch of the imaginat...   \n",
       "1  Twitter for iPhone  It’s a stupendous number. It’s joyous let’s ca...   \n",
       "2  Twitter for iPhone  Oh no the Dems are worried again. The only one...   \n",
       "3  Twitter for iPhone  Congratulations to wonderful Charles Payne on ...   \n",
       "4  Twitter for iPhone  I will be doing a News Conference at 10:00 A.M...   \n",
       "\n",
       "            created_at  favorite_count        id_str  \n",
       "0  06-05-2020 13:01:38         38831.0  1.268891e+18  \n",
       "1  06-05-2020 12:59:17         35164.0  1.268890e+18  \n",
       "2  06-05-2020 12:54:18         59423.0  1.268889e+18  \n",
       "3  06-05-2020 12:51:00         45021.0  1.268888e+18  \n",
       "4  06-05-2020 12:48:41         59473.0  1.268887e+18  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einlesen des Datensatzes, \"tweets_test\" ist nur eine Test Datei.\n",
    "train = pd.read_csv(\"trump_tweets.csv\", engine=\"python\", encoding=\"cp1252\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0        It is a stunner by any stretch of the imaginat...\n",
       "1        It’s a stupendous number. It’s joyous let’s ca...\n",
       "2        Oh no the Dems are worried again. The only one...\n",
       "3        Congratulations to wonderful Charles Payne on ...\n",
       "4        I will be doing a News Conference at 10:00 A.M...\n",
       "                               ...                        \n",
       "49350    My persona will never be that of a wallflower ...\n",
       "49351    New Blog Post: Celebrity Apprentice Finale and...\n",
       "49352    Donald Trump reads Top Ten Financial Tips on L...\n",
       "49353    Donald Trump will be appearing on The View tom...\n",
       "49354    Be sure to tune in and watch Donald Trump on L...\n",
       "Name: text, Length: 49355, dtype: object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hier wird die Tweet Variable deklariert\n",
    "tweets = train.text\n",
    "tweets.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    if (type(tweet) == str):\n",
    "        if (not re.search(r\"^RT.*$\", tweet) and not re.search(r\"^http.*$\", tweet)):\n",
    "            tweet = str(tweet).lower()\n",
    "            tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet, flags=re.MULTILINE)\n",
    "            tweet = re.sub(r'[_\"\\-;%()|.,+&=*%]', '', tweet)\n",
    "            tweet = re.sub(r'\\.', ' . ', tweet)\n",
    "            tweet = re.sub(r'\\!', ' !', tweet)\n",
    "            tweet = re.sub(r'\\?', ' ?', tweet)\n",
    "            tweet = re.sub(r'\\,', ' ,', tweet)\n",
    "            tweet = re.sub(r':', ' : ', tweet)\n",
    "            tweet = re.sub(r'#', ' # ', tweet)\n",
    "            tweet = re.sub(r'@', ' @ ', tweet)\n",
    "            tweet = re.sub(r'd .c .', 'd.c.', tweet)\n",
    "            tweet = re.sub(r'u .s .', 'd.c.', tweet)\n",
    "            tweet = re.sub(r' amp ', ' and ', tweet)\n",
    "            tweet = re.sub(r'pm', ' pm ', tweet)\n",
    "            tweet = re.sub(r'news', ' news ', tweet)\n",
    "            tweet = re.sub(r' . . . ', ' ', tweet)\n",
    "            tweet = re.sub(r' .  .  . ', ' ', tweet)\n",
    "            tweet = re.sub(r' ! ! ', ' ! ', tweet)\n",
    "            tweet = re.sub(r'&amp', 'and', tweet)\n",
    "            return tweet\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets säubern und alle Tweets in clean_tweets packen, dessen Länge > 0 ist.\n",
    "clean_tweets = []\n",
    "for tweet in tweets:\n",
    "    tweet = clean_tweet(tweet)\n",
    "    if tweet != \"none\":\n",
    "        if tweet != None:\n",
    "            if len(tweet) > 0:\n",
    "                clean_tweets.append(tweet)\n",
    "        \n",
    "len(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet0\n",
      "it is a stunner by any stretch of the imagination !  @ cnbc\n",
      "\n",
      "Tweet1\n",
      "it’s a stupendous number it’s joyous let’s call it like it is the market was right it’s stunning !  @ jimcramer   @ cnbc\n",
      "\n",
      "Tweet2\n",
      "oh no the dems are worried again the only one that can kill this comeback is sleepy joe biden !\n",
      "\n",
      "Tweet3\n",
      "congratulations to wonderful charles payne on having been so optimistic and therefore correct market up big ! !\n",
      "\n",
      "Tweet4\n",
      "i will be doing a  news  conference at 10 : 00 am on the jobs numbers ! white house\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prüfung, ob die Tweets gesäubert wurden:\n",
    "x = 0\n",
    "for i in range(x, x+5):\n",
    "    print(\"Tweet\" + str(i))\n",
    "    print(clean_tweets[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, die reguläre Ausdrücke in den jeweiligen Tweets findet und an eine List anhängt.\n",
    "def find_topic(liste, find_terms):\n",
    "    liste=[]\n",
    "    for i in range(len(clean_tweets)):\n",
    "        for word in clean_tweets[i].split():\n",
    "            find = re.findall(find_terms,word)\n",
    "            if find:\n",
    "                liste.append(clean_tweets[i])\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen für die jeweiligen Topics, die wir abfragen wollen. Zur besseren Übersicht wird für jedes Topic eine liste vergeben. Grundsätzlich würde eine leere Liste reichen.\n",
    "dems=[]\n",
    "republican=[]\n",
    "iran=[]\n",
    "election=[]\n",
    "obama=[]\n",
    "fake=[]\n",
    "china=[]\n",
    "media=[]\n",
    "maga=[]\n",
    "kag=[]\n",
    "america=[]\n",
    "interview=[]\n",
    "job=[]\n",
    "politic=[]\n",
    "fox=[]\n",
    "cnn=[]\n",
    "nbc=[]\n",
    "clinton=[]\n",
    "russian=[]\n",
    "covid=[]\n",
    "family=[]\n",
    "germany=[]\n",
    "industry=[]\n",
    "communism=[]\n",
    "korea=[]\n",
    "myself=[]\n",
    "military=[]\n",
    "health=[]\n",
    "wall=[]\n",
    "gun=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion auf die Topics anwenden, die wir verwenden wollen\n",
    "democrats = find_topic(dems, \"dems|democrats|democratic\")\n",
    "irans = find_topic(iran, \"iran\")\n",
    "republicans = find_topic(republican,\"republican\")\n",
    "elections = find_topic(election, \"elections|poll|campaign\")\n",
    "obamas = find_topic(obama, \"obama|barak|michelle|obamagate\")\n",
    "fakes = find_topic(fake,\"fake|fake news\")\n",
    "chinas = find_topic(china,\"china|chinese\")\n",
    "medias = find_topic(media,\"media|mainstream media\")\n",
    "magas = find_topic(maga,\"maga|make america great again\")\n",
    "kags = find_topic(kag,\"kag|keep america great\")\n",
    "americas = find_topic(america,\"america|american|usa|united states\")\n",
    "interviews = find_topic(interview,\"interview|interviews\")\n",
    "jobs = find_topic(job,\"jobs|work\")\n",
    "politics = find_topic(politic,\"politics|politic\")\n",
    "foxs = find_topic(fox,\"fox|fox news\")\n",
    "cnns = find_topic(cnn,\"cnn|cnn news\")\n",
    "nbcs = find_topic(nbc,\"nbc|nbc news\")\n",
    "clintons = find_topic(clinton,\"hillary|clinton|bill\")\n",
    "russians = find_topic(russian,\"russians|putin|russian|russia\")\n",
    "covids = find_topic(covid,\"flu|corona|covid|virus|pandemic|chinese virus\")\n",
    "familys = find_topic(family,\"ivanka|trump|melania\")\n",
    "germanys = find_topic(germany,\"german|germany|merkel\")\n",
    "industrys = find_topic(industry,\"industry|industrial\")\n",
    "koreas = find_topic(korea,\"korea\")\n",
    "myselfs = find_topic(myself,\"donald|trump\")\n",
    "militarys = find_topic(military,\"military\")\n",
    "healths = find_topic(health,\"health|care\")\n",
    "walls = find_topic(wall,\"border|wall|mexico\")\n",
    "guns = find_topic(gun,\"gun|weapon|rifle|shooting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "covids = find_topic(covid,\"flu|corona|covid|virus|pandemic|chinese virus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Markovify-Modells, welches gleich in ein Json-Format umgewandelt wird.\n",
    "markov_dems = markovify.Text(democrats, state_size = 3,well_formed=False).to_json()\n",
    "markov_guns = markovify.Text(guns, state_size = 3, well_formed=False).to_json()\n",
    "markov_walls = markovify.Text(walls, state_size = 3, well_formed=False).to_json()\n",
    "markov_healths = markovify.Text(healths, state_size = 3, well_formed=False).to_json()\n",
    "markov_militarys = markovify.Text(militarys, state_size = 3, well_formed=False).to_json()\n",
    "markov_myselfs = markovify.Text(myselfs, state_size = 3, well_formed=False).to_json()\n",
    "markov_koreas = markovify.Text(koreas, state_size = 3, well_formed=False).to_json()\n",
    "markov_industrys = markovify.Text(industrys, state_size = 3, well_formed=False).to_json()\n",
    "markov_germanys = markovify.Text(germanys, state_size = 3, well_formed=False).to_json()\n",
    "markov_familys = markovify.Text(familys, state_size = 3, well_formed=False).to_json()\n",
    "markov_covids = markovify.Text(covids, state_size = 3, well_formed=False).to_json()\n",
    "markov_russians = markovify.Text(russians, state_size = 3, well_formed=False).to_json()\n",
    "markov_clintons = markovify.Text(clintons, state_size = 3, well_formed=False).to_json()\n",
    "markov_nbcs = markovify.Text(nbcs, state_size = 3, well_formed=False).to_json()\n",
    "markov_cnns = markovify.Text(cnns, state_size = 3, well_formed=False).to_json()\n",
    "markov_foxs = markovify.Text(foxs, state_size = 3, well_formed=False).to_json()\n",
    "markov_politics = markovify.Text(politics, state_size = 3, well_formed=False).to_json()\n",
    "markov_jobs = markovify.Text(jobs, state_size = 3, well_formed=False).to_json()\n",
    "markov_interviews = markovify.Text(interviews, state_size = 3, well_formed=False).to_json()\n",
    "markov_americas = markovify.Text(americas, state_size = 3, well_formed=False).to_json()\n",
    "markov_kags = markovify.Text(kags, state_size = 3, well_formed=False).to_json()\n",
    "markov_magas = markovify.Text(magas, state_size = 3, well_formed=False).to_json()\n",
    "markov_medias = markovify.Text(medias, state_size = 3, well_formed=False).to_json()\n",
    "markov_chinas = markovify.Text(chinas, state_size = 3, well_formed=False).to_json()\n",
    "markov_fakes = markovify.Text(fakes, state_size = 3, well_formed=False).to_json()\n",
    "markov_obamas = markovify.Text(obamas, state_size = 3, well_formed=False).to_json()\n",
    "markov_elections = markovify.Text(elections, state_size = 3, well_formed=False).to_json()\n",
    "markov_republicans = markovify.Text(republicans, state_size = 3, well_formed=False).to_json()\n",
    "markov_irans = markovify.Text(irans, state_size = 3, well_formed=False).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-df7549b04562>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Abspeichern und Export der einzelnen Modelle als \".txt\"-Datei.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'markov_dems.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdems_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'markov_healths.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Abspeichern und Export der einzelnen Modelle als \".txt\"-Datei.\n",
    "with open('markov_dems.txt', 'w') as outfile:\n",
    "    json.dump(dems_json, outfile)\n",
    "    \n",
    "with open('markov_healths.txt', 'w') as outfile:\n",
    "    json.dump(markov_healths, outfile)\n",
    "    \n",
    "with open('markov_iran.txt', 'w') as outfile:\n",
    "    json.dump(markov_irans, outfile)\n",
    "    \n",
    "with open('markov_republicans.txt', 'w') as outfile:\n",
    "    json.dump(markov_republicans, outfile)\n",
    "    \n",
    "with open('markov_elections.txt', 'w') as outfile:\n",
    "    json.dump(markov_elections, outfile)\n",
    "    \n",
    "with open('markov_obamas.txt', 'w') as outfile:\n",
    "    json.dump(markov_obamas, outfile)\n",
    "    \n",
    "with open('markov_fakes.txt', 'w') as outfile:\n",
    "    json.dump(markov_fakes, outfile)\n",
    "    \n",
    "with open('markov_china.txt', 'w') as outfile:\n",
    "    json.dump(markov_chinas, outfile)\n",
    "    \n",
    "with open('markov_media.txt', 'w') as outfile:\n",
    "    json.dump(markov_medias, outfile)\n",
    "    \n",
    "with open('markov_maga.txt', 'w') as outfile:\n",
    "    json.dump(markov_magas, outfile)\n",
    "    \n",
    "with open('markov_kag.txt', 'w') as outfile:\n",
    "    json.dump(markov_kags, outfile)\n",
    "    \n",
    "with open('markov_america.txt', 'w') as outfile:\n",
    "    json.dump(markov_americas, outfile)\n",
    "    \n",
    "with open('markov_interview.txt', 'w') as outfile:\n",
    "    json.dump(markov_interviews, outfile)\n",
    "    \n",
    "with open('markov_jobs.txt', 'w') as outfile:\n",
    "    json.dump(markov_jobs, outfile)\n",
    "    \n",
    "with open('markov_politics.txt', 'w') as outfile:\n",
    "    json.dump(markov_politics, outfile)\n",
    "    \n",
    "with open('markov_fox.txt', 'w') as outfile:\n",
    "    json.dump(markov_foxs, outfile)\n",
    "    \n",
    "with open('markov_cnn.txt', 'w') as outfile:\n",
    "    json.dump(markov_cnns, outfile)\n",
    "    \n",
    "with open('markov_nbc.txt', 'w') as outfile:\n",
    "    json.dump(markov_nbcs, outfile)\n",
    "    \n",
    "with open('markov_clinton.txt', 'w') as outfile:\n",
    "    json.dump(markov_clintons, outfile)\n",
    "    \n",
    "with open('markov_russia.txt', 'w') as outfile:\n",
    "    json.dump(markov_russians, outfile)\n",
    "    \n",
    "with open('markov_covid.txt', 'w') as outfile:\n",
    "    json.dump(markov_covids, outfile)\n",
    "    \n",
    "with open('markov_family.txt', 'w') as outfile:\n",
    "    json.dump(markov_familys, outfile)\n",
    "    \n",
    "with open('markov_germany.txt', 'w') as outfile:\n",
    "    json.dump(markov_germanys, outfile)\n",
    "    \n",
    "with open('markov_industry.txt', 'w') as outfile:\n",
    "    json.dump(markov_industrys, outfile)\n",
    "    \n",
    "with open('markov_korea.txt', 'w') as outfile:\n",
    "    json.dump(markov_koreas, outfile)\n",
    "    \n",
    "with open('markov_myself.txt', 'w') as outfile:\n",
    "    json.dump(markov_myselfs, outfile)\n",
    "    \n",
    "with open('markov_military.txt', 'w') as outfile:\n",
    "    json.dump(markov_militarys, outfile)\n",
    "    \n",
    "with open('markov_walls.txt', 'w') as outfile:\n",
    "    json.dump(markov_walls, outfile)\n",
    "    \n",
    "with open('markov_guns.txt', 'w') as outfile:\n",
    "    json.dump(markov_guns, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "via @ news maxmedia @ dpatten32 time for trump to get to 3 even though they said\n",
      "melania and i extend our deepest condolences to president reuven rivlin and the entire trump family i want to go to jail for flying trump flag breitbart\n"
     ]
    }
   ],
   "source": [
    "# Durch diese Zeile können wir unsere Modelle wieder importieren.\n",
    "reconstituted_model = markovify.Text.from_json(markov_familys)\n",
    "print(reconstituted_model.make_short_sentence(140))\n",
    "print(reconstituted_model.make_sentence_with_start('melania'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
