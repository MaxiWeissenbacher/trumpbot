{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump Bot: Topic Clustering mit TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Datensatzes, \"trump_tweets.csv\"\n",
    "#cp1252 encoding nur für MacOS\n",
    "train = pd.read_csv(\"trump_tweets.csv\", engine=\"python\", encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>It is a stunner by any stretch of the imaginat...</td>\n",
       "      <td>06-05-2020 13:01:38</td>\n",
       "      <td>38831.0</td>\n",
       "      <td>1.268891e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>It’s a stupendous number. It’s joyous let’s ca...</td>\n",
       "      <td>06-05-2020 12:59:17</td>\n",
       "      <td>35164.0</td>\n",
       "      <td>1.268890e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Oh no the Dems are worried again. The only one...</td>\n",
       "      <td>06-05-2020 12:54:18</td>\n",
       "      <td>59423.0</td>\n",
       "      <td>1.268889e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Congratulations to wonderful Charles Payne on ...</td>\n",
       "      <td>06-05-2020 12:51:00</td>\n",
       "      <td>45021.0</td>\n",
       "      <td>1.268888e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I will be doing a News Conference at 10:00 A.M...</td>\n",
       "      <td>06-05-2020 12:48:41</td>\n",
       "      <td>59473.0</td>\n",
       "      <td>1.268887e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  It is a stunner by any stretch of the imaginat...   \n",
       "1  Twitter for iPhone  It’s a stupendous number. It’s joyous let’s ca...   \n",
       "2  Twitter for iPhone  Oh no the Dems are worried again. The only one...   \n",
       "3  Twitter for iPhone  Congratulations to wonderful Charles Payne on ...   \n",
       "4  Twitter for iPhone  I will be doing a News Conference at 10:00 A.M...   \n",
       "\n",
       "            created_at  favorite_count        id_str  \n",
       "0  06-05-2020 13:01:38         38831.0  1.268891e+18  \n",
       "1  06-05-2020 12:59:17         35164.0  1.268890e+18  \n",
       "2  06-05-2020 12:54:18         59423.0  1.268889e+18  \n",
       "3  06-05-2020 12:51:00         45021.0  1.268888e+18  \n",
       "4  06-05-2020 12:48:41         59473.0  1.268887e+18  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49355, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0        It is a stunner by any stretch of the imaginat...\n",
       "1        It’s a stupendous number. It’s joyous let’s ca...\n",
       "2        Oh no the Dems are worried again. The only one...\n",
       "3        Congratulations to wonderful Charles Payne on ...\n",
       "4        I will be doing a News Conference at 10:00 A.M...\n",
       "                               ...                        \n",
       "49350    My persona will never be that of a wallflower ...\n",
       "49351    New Blog Post: Celebrity Apprentice Finale and...\n",
       "49352    Donald Trump reads Top Ten Financial Tips on L...\n",
       "49353    Donald Trump will be appearing on The View tom...\n",
       "49354    Be sure to tune in and watch Donald Trump on L...\n",
       "Name: text, Length: 49355, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hier wird die Tweet Variable deklariert\n",
    "tweets = train.text\n",
    "tweets.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets \"säubern\" mit regulären Ausdrücken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    if (type(tweet) == str):\n",
    "        if (not re.search(r\"^RT.*$\", tweet) and not re.search(r\"^http.*$\", tweet)):\n",
    "            tweet = str(tweet).lower()\n",
    "            tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet, flags=re.MULTILINE)\n",
    "            tweet = re.sub(r'[_\"\\-;%()|.,+&=*%]', '', tweet)\n",
    "            tweet = re.sub(r'\\.', ' . ', tweet)\n",
    "            tweet = re.sub(r'\\!', ' !', tweet)\n",
    "            tweet = re.sub(r'\\?', ' ?', tweet)\n",
    "            tweet = re.sub(r'\\,', ' ,', tweet)\n",
    "            tweet = re.sub(r':', ' : ', tweet)\n",
    "            tweet = re.sub(r'#', ' # ', tweet)\n",
    "            tweet = re.sub(r'@', ' @ ', tweet)\n",
    "            tweet = re.sub(r'd .c .', 'd.c.', tweet)\n",
    "            tweet = re.sub(r'u .s .', 'd.c.', tweet)\n",
    "            tweet = re.sub(r' amp ', ' and ', tweet)\n",
    "            tweet = re.sub(r'pm', ' pm ', tweet)\n",
    "            tweet = re.sub(r'news', ' news ', tweet)\n",
    "            tweet = re.sub(r' . . . ', ' ', tweet)\n",
    "            tweet = re.sub(r' .  .  . ', ' ', tweet)\n",
    "            tweet = re.sub(r' ! ! ', ' ! ', tweet)\n",
    "            tweet = re.sub(r'&amp', 'and', tweet)\n",
    "            return tweet\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38098"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets säubern und alle Tweets in clean_tweets packen, dessen Länge > 0 ist.\n",
    "clean_tweets = []\n",
    "for tweet in tweets:\n",
    "    tweet = clean_tweet(tweet)\n",
    "    if tweet != \"none\":\n",
    "        if tweet != None:\n",
    "            if len(tweet) > 0:\n",
    "                clean_tweets.append(tweet)\n",
    "        \n",
    "len(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet0\n",
      "it is a stunner by any stretch of the imagination !  @ cnbc\n",
      "\n",
      "Tweet1\n",
      "it’s a stupendous number it’s joyous let’s call it like it is the market was right it’s stunning !  @ jimcramer   @ cnbc\n",
      "\n",
      "Tweet2\n",
      "oh no the dems are worried again the only one that can kill this comeback is sleepy joe biden !\n",
      "\n",
      "Tweet3\n",
      "congratulations to wonderful charles payne on having been so optimistic and therefore correct market up big ! !\n",
      "\n",
      "Tweet4\n",
      "i will be doing a  news  conference at 10 : 00 am on the jobs numbers ! white house\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prüfung, ob die Tweets gesäubert wurden:\n",
    "x = 0\n",
    "for i in range(x, x+5):\n",
    "    print(\"Tweet\" + str(i))\n",
    "    print(clean_tweets[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berechnung der TF-IDF Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Berechnung der TF-IDF Werte\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfidf_vectors=tfidf_vectorizer.fit_transform(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   tfidf\n",
      "stunner         0.528110\n",
      "stretch         0.508383\n",
      "imagination     0.416084\n",
      "cnbc            0.363452\n",
      "any             0.259381\n",
      "...                  ...\n",
      "fitbafan        0.000000\n",
      "fitch           0.000000\n",
      "fiteswithheart  0.000000\n",
      "fitn            0.000000\n",
      "élysée          0.000000\n",
      "\n",
      "[37181 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#So sieht ein einzelner Vektor, nach absteigenden TF-IDF Werten sortiert, aus\n",
    "example_vector=tfidf_vectors[0]\n",
    "df = pd.DataFrame(example_vector.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "print(df.sort_values(by=[\"tfidf\"],ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Umwandlung der Werte in eine Matrix um die pca-Metode auf die Werte anwenden zu können\n",
    "matrix = tfidf_vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustern der Tweets in Gruppen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit der Hauptkomponentenanalyse (PCA) reduzieren wir die Dimension eines jeden Tweets auf 1.\n",
    "pca = PCA(n_components=1, random_state = 2)\n",
    "pca_tweets = pca.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl:  38098\n",
      "[[-0.05649444]\n",
      " [-0.04702602]\n",
      " [-0.06852488]\n",
      " ...\n",
      " [ 0.00189099]\n",
      " [-0.04942379]\n",
      " [-0.06038127]]\n"
     ]
    }
   ],
   "source": [
    "# Wir sehen, dass wir immer noch fast die gleiche Anzahl an Tweets haben. \n",
    "# Jeden Tweet stellt jetzt allerdings nur noch eine Zahl dar:\n",
    "print(\"Anzahl: \", len(pca_tweets))\n",
    "print(pca_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ähnliche Tweets gruppieren mit der K-Means-Methode.\n",
    "# n_clusters gibt an, wieviele unterschiedliche Gruppen wir wollen\n",
    "kmeans = KMeans(n_clusters=4, max_iter = 1000, n_init = 20, random_state=2).fit(pca_tweets)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16950\n",
       "3    16205\n",
       "2     3863\n",
       "1     1080\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wie viele Tweets sind in jeder Gruppe enthalten:\n",
    "pd.DataFrame(labels)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords aufzählen, damit diese nicht bei den meist vorkommenden Wörter aufgelistet werden:\n",
    "stop_words = ['be','on','!','at','.',':','...','@',',','#','will','.m','in','a','the','with','to','by','and','my','is',\n",
    "              'of','for','new','via','are','that','has','have','all','as','it','so','they','do','he','just','this',\n",
    "              'was','who','your','from','his','about','get','but','am','up','if','can','would','than','should','dont',\n",
    "              'had','or','were','did','there','got','even','its','an','i', 'not', 'our', 'we','you', '?','no','their', 'us','rt','great',\n",
    "             'realdonaldtrump', 'trump', 'very', 'thank', 'thanks', 'president', 'donald', 'what', 'news', 'me', 'never', 'out', 'now', 'good',\n",
    "             'when', 'like', 'one', 'more', 'run', 'time', 'best', 'going', 'much', 'want', 'big', 'make', 'again', 'many', 'been', 'today', 'him', 'pm', 'true',\n",
    "             'mr', 'them', 'only', 'back', 'yes', 'need', 'why' , 'tonight', 'over', 'really', 'how', 'other', 'being', 'see', 'show', 'doing', 'think', 'must',\n",
    "            'trump2016', 'makeamericagreatagain', 'apprenticenbc', 'fox', 'foxandfriends', 'can\\'t', 'don\\'t', '00', 'i\\'m', 'know', 'celebapprentice', 'love', 'vote',\n",
    "             'america', 'her', '7', 'watch', 'please', '2016', 'it\\'s', 'tomorrow', 'she', 'country', 'people', 'go', 'first', 'soon', 'nice', 'years', 'hope', 'needs',\n",
    "             'you\\'re', 'work', 'keep', 'day', 'job', 'better', 'working', 'man', 'could', 'ever', 'done', 'say', 'amazing', 'support', 'bad', 'happy', 'believe',\n",
    "             'right', 'well', 'always', 'last', 'amazing', 'win', 'which', 'because', 'way', 'real', 'u', '–', 'next', 'you\\'ve', 'agree', 'running', 'wait', 'total',\n",
    "             'said', '“', '“donald', '10', 'words', 'wonderful', 'american', 'hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für jede Gruppe die am meisten vorkommenden Wörter finden:\n",
    "def most_common_words(group, n_words):\n",
    "    vocab = {} # das Vokabular für jede Gruppe\n",
    "    for i in range(len(clean_tweets)):\n",
    "        if labels[i] == group:\n",
    "            for word in clean_tweets[i].split():\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = 1\n",
    "                else:\n",
    "                    vocab[word] += 1\n",
    "      \n",
    "    # Sortiere die am häufigst vorkommenden Wörter\n",
    "    sorted_vocab = sorted(vocab.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top_n_words = []\n",
    "    for word, value in sorted_vocab:\n",
    "        if word not in stop_words:\n",
    "            top_n_words.append(word)\n",
    "        if len(top_n_words) == n_words:\n",
    "            break\n",
    "    print(top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruppe  1 : \n",
      "['obama', 'interview', 'apprentice', 'night', 'golf', 'jobs', 'course', 'business', 'looking', 'congratulations']\n",
      "Gruppe  2 : \n",
      "['maga', 'kag2020', 'poll', 'americafirst', 'carolina', 'florida', 'honor', 'iowa', 'hampshire', 'pennsylvania']\n",
      "Gruppe  3 : \n",
      "['republican', 'poll', 'business', 'night', 'god', 'look', 'honor', 'sir', 'proud', 'down']\n",
      "Gruppe  4 : \n",
      "['obama', 'democrats', 'fake', 'china', 'border', 'media', 'deal', 'world', 'states', 'united']\n"
     ]
    }
   ],
   "source": [
    "# die am meisten vorkommenden Worte in jeder Gruppe:\n",
    "groups = len(np.unique(labels))\n",
    "for i in range(groups):\n",
    "    print(\"Gruppe \", i+1,\": \")\n",
    "    most_common_words(i, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch diese Gruppen können übergreifende Topics deklariert werden. Zum Beispiel wäre ein mögliches Topic für Gruppe 2 \"poll\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tweet_group(group, n_tweets):\n",
    "    '''Prints the first n_tweets in a group'''\n",
    "    count = 1\n",
    "    for i in range(len(clean_tweets)):\n",
    "        if labels[i] == group:\n",
    "            print(\"#{}: {}\".format(count, clean_tweets[i]))\n",
    "            count += 1\n",
    "            if count == n_tweets+1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruppe # 1\n",
      "#1: congratulations to wonderful charles payne on having been so optimistic and therefore correct market up big ! !\n",
      "#2: this is an amazing jobs report ! edward lawrence  @ fox news \n",
      "#3: i am so stunned i’ve never seen numbers like this and i’ve been doing this for 30 years ! steve m  @ mariabartiromo\n",
      "#4: these numbers are incredible !  @ mariabartiromo\n",
      "#5: really big jobs report great going president trump kidding but true !\n",
      "\n",
      "Gruppe # 2\n",
      "#1: thank you matt ! \n",
      "#2: thank you mark ! \n",
      "#3: 100 correct thank you tom ! \n",
      "#4: thank you cowboys see you in new mexico ! \n",
      "#5: thank you lou ! \n",
      "\n",
      "Gruppe # 3\n",
      "#1: thanks for your invaluable help in getting a great man passed to run voice of america trying for 25 years and you got it done jim idaho is proud of you ! \n",
      "#2: so great to have michael home just arrived very exciting thank you to iran don’t wait until after us election to make the big deal i’m going to win you’ll make a better deal now ! \n",
      "#3: unrelated i gave alaska anwr major highways and more get any candidate ready good or bad i don’t care i’m endorsing if you have a pulse i’m with you !\n",
      "#4: michael is tough smart and loves our country this has been a big battle in congress for 25 years thank you to our great republican senate !  @ senatecloakroom\n",
      "#5: you don’t burn churches in america !\n",
      "\n",
      "Gruppe # 4\n",
      "#1: it is a stunner by any stretch of the imagination !  @ cnbc\n",
      "#2: it’s a stupendous number it’s joyous let’s call it like it is the market was right it’s stunning !  @ jimcramer   @ cnbc\n",
      "#3: oh no the dems are worried again the only one that can kill this comeback is sleepy joe biden !\n",
      "#4: i will be doing a  news  conference at 10 : 00 am on the jobs numbers ! white house\n",
      "#5: true steve is a great senator need him badly in washington complete and total endorsement ! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Die ersten paar Tweets in jeder Gruppe:\n",
    "n_tweets = 5\n",
    "for i in range(groups):\n",
    "    print(\"Gruppe #\",i+1)\n",
    "    print_tweet_group(i,n_tweets)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
